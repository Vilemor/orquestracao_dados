# orquestracao_dados

RepositÃ³rio de treinamento para orquestraÃ§Ã£o e manipulaÃ§Ã£o de dados com PySpark.

---

## ğŸ“š Objetivo

Este projeto tem como principal objetivo oferecer um ambiente didÃ¡tico e prÃ¡tico para aprendizado e desenvolvimento de pipelines de dados utilizando PySpark, com foco em:

- ConstruÃ§Ã£o e orquestraÃ§Ã£o de pipelines de ETL/ELT locais, trabalhando com arquivos CSV de dados brutos.
- Tratamento e transformaÃ§Ã£o progressiva dos dados, aplicando boas prÃ¡ticas de engenharia de dados.
- ExploraÃ§Ã£o de conceitos de camadas de dados, incluindo Stage, SOR, SOT e Mesh.
- Testes unitÃ¡rios para garantir qualidade e confiabilidade das transformaÃ§Ãµes.
- IntegraÃ§Ã£o contÃ­nua via GitHub Actions para validaÃ§Ã£o automÃ¡tica do cÃ³digo e pipeline.
- OtimizaÃ§Ã£o de performance Spark para processamento eficiente em ambiente local.

---

## ğŸ—ï¸ Arquitetura e Camadas do Pipeline

O pipeline segue uma arquitetura em camadas, onde cada etapa Ã© responsÃ¡vel por uma transformaÃ§Ã£o especÃ­fica:

| Camada   | DescriÃ§Ã£o                                                  | SaÃ­da                                   |
|----------|------------------------------------------------------------|-----------------------------------------|
| **STAGE -> SOR**  | Leitura e parsing inicial dos dados brutos (CSV). | DataFrame com tipos e formato corretos.|
| **SOR -> SOT**  | Tratamento avanÃ§ado, enriquecimento e validaÃ§Ã£o dos dados. | Dados prontos para anÃ¡lise e uso.       |
| **SOT -> MESH** | GeraÃ§Ã£o do JSON/PARQUET final tratado, formato consumÃ­vel para APIs ou downstream. | Arquivos JSON prontos para consumo.    |

---

## âš™ï¸ Tecnologias e Ferramentas

- **Python 3.10+**  
- **PySpark** para processamento distribuÃ­do e manipulaÃ§Ã£o de grandes volumes de dados  
- **Faker** para geraÃ§Ã£o de dados sintÃ©ticos e testes  
- **pytest** para testes unitÃ¡rios  
- **Poetry** para gerenciamento de dependÃªncias e ambiente  
- **GitHub Actions** para integraÃ§Ã£o contÃ­nua (CI/CD) com validaÃ§Ã£o automÃ¡tica  

---

## ğŸ“ Estrutura do RepositÃ³rio

ğŸ“„ .gitignore
ğŸ“„ LICENSE
ğŸ“„ README.md
ğŸ“‚ data
â”‚ â””â”€â”€ ğŸ“„ dados_brutos.csv
ğŸ“‚ outputs
ğŸ“‚ .github
â”‚ ğŸ“‚ workflows
    â”‚ â””â”€â”€ ğŸ“„ ci.yml
ğŸ“‚ tests
â”‚ â”œâ”€â”€ ğŸ“„ init.py
â”‚ â”œâ”€â”€ ğŸ“„ test_end_to_end.py
â”‚ â”œâ”€â”€ ğŸ“„ test_mesh.py
â”‚ â”œâ”€â”€ ğŸ“„ test_sor.py
â”‚ â”œâ”€â”€ ğŸ“„ test_sot.py
â”‚ â””â”€â”€ ğŸ“„ test_stage.py
ğŸ“‚ src
â””â”€â”€ pipeline
â”œâ”€â”€ ğŸ“„ init.py
â”œâ”€â”€ ğŸ“„ sor_sot.py
â”œâ”€â”€ ğŸ“„ sot_mesh.py
â”œâ”€â”€ ğŸ“„ stage_sor.py
ğŸ“‚ utils
â””â”€â”€ ğŸ“„ utils.py
â””â”€â”€ ğŸ“„ json_logger.py
---

## JSON Logger Python


### Logger estruturado em JSON para aplicaÃ§Ãµes Python, com agrupamento visual, contexto, rastreamento de exceÃ§Ãµes e gravaÃ§Ã£o opcional em arquivo.


### Exemplo de Uso
```python
from json_logger import log_json

# Log de sucesso (INFO)
log_json("Processo finalizado com sucesso.")

# Log de aviso (WARNING)
log_json("Arquivo de configuraÃ§Ã£o nÃ£o encontrado, usando valores padrÃ£o.", level="WARNING")

# Log de erro (ERROR)
try:
    1 / 0
except Exception as e:
    log_json("Erro ao executar operaÃ§Ã£o crÃ­tica.", level="ERROR", exc=e)
```


### Exemplo de SaÃ­da

```json
==================== ORQUESTRACAO ==================== 
Log de Sucesso (INFO)
{ 
    "timestamp": "2025-05-18T15:03:02.700714-03:00", 
    "level": "INFO", 
    "log_groups": "orquestracao", 
    "message": "Processo finalizado com sucesso.",
    "execution_id": "d4b824e1-c2bb-4c4f-99d0-6ce72651beea",
    "function": "__main__", 
    "file": "main.py:10" 
}

Log de Aviso (WARNING)
{ 
    "timestamp": "2025-05-18T15:03:03.123456-03:00",
    "level": "WARNING", 
    "log_groups": "orquestracao", 
    "message": "Arquivo de configuraÃ§Ã£o nÃ£o encontrado, usando valores padrÃ£o.", 
    "execution_id": "d4b824e1-c2bb-4c4f-99d0-6ce72651beea", 
    "function": "__main__", 
    "file": "main.py:13" 
}

Log de Erro (ERROR)

{
    "timestamp": "2025-05-18T15:15:51.738759-03:00",
    "level": "ERROR",
    "log_groups": "orquestracao",
    "message": "Erro ao executar operaÃ§Ã£o crÃ­tica.",
    "execution_id": "d4b824e1-c2bb-4c4f-99d0-6ce72651beea",
    "function": "main",
    "file": "main.py",
    "context": {
        "input": "1/0"
    },
    "error_location": "main.py:17",
    "stacktrace": "ZeroDivisionError: division by zero"
}
```

### Recursos
- Agrupamento visual por grupo de log (group)
- Contexto adicional via parÃ¢metro context
- Rastreamento detalhado de exceÃ§Ãµes (exc)
- GravaÃ§Ã£o opcional em arquivo (log_to_file)
- IdentificaÃ§Ã£o de funÃ§Ã£o, arquivo e linha do log